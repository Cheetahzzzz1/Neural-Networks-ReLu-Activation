# Neural-Networks-ReLu-Activation

# Overview

This assignment focuses on implementing and analyzing a 3

# Problem Descriptions

**Problem 1: Verifying not(XOR) with a Neural Network**

We will verify that a neural network with sigmoid activation functions approximates the not(XOR) function. This involves:-

1. Computing the outputs of the hidden nodes for the given inputs.
2. Calculating the final outputs ‚ÑéùúÉ(ùë•) for each pair.

The objective of this problem was to demonstrate that the neural network correctly approximates the not(XOR) function for all input combinations.

**Problem 2: Convolutional and Max-pooling operations**

We will perform computations involving a convolutional layer and a max-pooling layer. The kernel and input data are provided as follows:-

